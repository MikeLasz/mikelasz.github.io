---
---

@string{aps = {American Physical Society,}}

@article{miau,
  title = {Set-Membership Inference Attacks using Data Watermarking},
  author = {Laszkiewicz, Mike and Lukovnikov, Denis and Lederer, Johannes and Fischer, Asja},
  journal={(Preprint)},
  year={2023},
  preview={bushy.png},
  selected={false},
  abstract={In this work, we propose a set–membership inference attack for generative models using deep image watermarking techniques. In particular,we demonstrate how conditional sampling from a generative model can reveal the watermark that was injected into parts of the training data. Our empirical results demonstrate that the proposed watermarking technique is as a principled approach for detecting the non-consensual use of image data in training generative models.
}
  }
  
@article{flipad,
  title = {Single-Model Attribution of Generative Models Through Final-Layer Inversion},
  author = {Laszkiewicz, Mike and Ricker, Jonas and Lederer, Johannes and Fischer, Asja},
  journal={(Under Review)},
  year={2023},
  selected={true},
  preview={flipad_logo.png},
  abstract={Recent groundbreaking developments on generative modeling have sparked interest in practical single-model attribution. Such methods predict whether a sample was generated by a specific generator or not, for instance, to prove intellectual property theft. However, previous works are either limited to the closed-world setting or require undesirable changes of the generative model. We address these shortcomings by proposing FLIPAD, a new approach for single-model attribution in the open-world setting based on final-layer inversion and anomaly detection. We show that the utilized final-layer inversion can be reduced to a convex lasso optimization problem, making our approach theoretically sound and computationally efficient. The theoretical findings are accompanied by an experimental study demonstrating the effectiveness of our approach, outperforming the existing methods.
},
  pdf={https://arxiv.org/pdf/2306.06210.pdf}
  }
  
@InProceedings{mtaf,
  title = 	 {Marginal Tail-Adaptive Normalizing Flows},
  author =       {Laszkiewicz, Mike and Lederer, Johannes and Fischer, Asja},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning (ICML)},
  pages = 	 {12020--12048},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  selected={true},
  preview={mtaf_logo.png},
  abstract={Learning the tail behavior of a distribution is a notoriously difficult problem. By definition, the number of samples from the tail is small, and deep generative models, such as normalizing flows, tend to concentrate on learning the body of the distribution. In this paper, we focus on improving the ability of normalizing flows to correctly capture the tail behavior and, thus, form more accurate models. We prove that the marginal tailedness of an autoregressive flow can be controlled via the tailedness of the marginals of its base distribution. This theoretical insight leads us to a novel type of flows based on flexible base distributions and data-driven linear layers. An empirical analysis shows that the proposed method improves on the accuracy{—}especially on the tails of the distribution{—}and is able to generate heavy-tailed data. We demonstrate its application on a weather and climate example, in which capturing the tail behavior is essential.
},
  pdf={https://proceedings.mlr.press/v162/laszkiewicz22a/laszkiewicz22a.pdf}
}

@InProceedings{copula,
  title={Copula-based normalizing flows},
  abstract={Normalizing flows, which learn a distribution by
transforming the data to samples from a Gaussian
base distribution, have proven powerful density
approximators. But their expressive power is limited by this choice of the base distribution. We,
therefore, propose to generalize the base distribution to a more elaborate copula distribution to
capture the properties of the target distribution
more accurately. In a first empirical analysis, we
demonstrate that this replacement can dramatically improve the vanilla normalizing flows in
terms of flexibility, stability, and effectivity for
heavy-tailed data. Our results suggest that the
improvements are related to an increased local
Lipschitz-stability of the learned flow.},
  pdf={https://arxiv.org/pdf/2107.07352.pdf},
  author={Laszkiewicz, Mike and Lederer, Johannes and Fischer, Asja},
  booktitle={Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+)
},
  year={2021},
  selected={true},
  preview={copula_nfs_logo.png}
}

@InProceedings{thav,
  title={Thresholded adaptive validation: Tuning the graphical lasso for graph recovery},
  author={Laszkiewicz, Mike and Fischer, Asja and Lederer, Johannes},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1864--1872},
  year={2021},
  organization={PMLR},
  selected={true},
  preview={thav_logo.png},
  abstract={Many Machine Learning algorithms are formulated as regularized optimization problems,
but their performance hinges on a regularization parameter that needs to be calibrated
to each application at hand. In this paper,
we propose a general calibration scheme for
regularized optimization problems and apply
it to the graphical lasso, which is a method
for Gaussian graphical modeling. The scheme
is equipped with theoretical guarantees and
motivates a thresholding pipeline that can improve graph recovery. Moreover, requiring at
most one line search over the regularization
path, the calibration scheme is computationally more efficient than competing schemes
that are based on resampling. Finally, we
show in simulations that our approach can
improve on the graph recovery of other approaches considerably.},
  pdf={http://proceedings.mlr.press/v130/laszkiewicz21a/laszkiewicz21a.pdf}
}